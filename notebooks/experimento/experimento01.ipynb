{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d1cf7887",
   "metadata": {},
   "source": [
    "# Experimento de analise geral.\n",
    "\n",
    "## TL;DR\n",
    "\n",
    "nesse notebook estudamos como toda nossa exploração se combina e gera uma analise que abrange um escopo maior para \n",
    "\n",
    "## Objetivo\n",
    "\n",
    "estudar como carda tipo de análise desde como cada tipo de pré processamento afeta os dados, até a analise das métricas que cada um dos aplicação dos métodos de clusterização\n",
    "\n",
    "## Dados\n",
    "\n",
    "CSV's\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87595eb3",
   "metadata": {},
   "source": [
    "# Experimento 01"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fda28ca5",
   "metadata": {},
   "source": [
    "## Import das Bibliotecas\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "5213791c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "# Bloco 1 - K-Means tradicional com distância Euclidiana\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import matplotlib.cm as cm\n",
    "# Bloco 2 - K-Means com distância DTW (tslearn)\n",
    "from tslearn.clustering import TimeSeriesKMeans\n",
    "from tslearn.preprocessing import TimeSeriesScalerMeanVariance\n",
    "# Bloco 3 - Hierarchical Clustering com DTW\n",
    "from scipy.cluster.hierarchy import linkage, fcluster\n",
    "from tslearn.metrics import cdist_dtw\n",
    "# Bloco 4 - DBA-KMeans (K-Means com DTW Barycenter Averaging)\n",
    "from tslearn.clustering import TimeSeriesKMeans\n",
    "from tslearn.preprocessing import TimeSeriesScalerMeanVariance\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn.metrics import silhouette_score, calinski_harabasz_score, davies_bouldin_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "9bb1fccd",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_original = pd.read_csv('../../data/rafaelDB.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "241c3a56",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_metricas = pd.DataFrame(columns=[\n",
    "    'Metodo',\n",
    "    'Ajuste'\n",
    "    'n_clusters',\n",
    "    'Silhouette Score',\n",
    "    'Calinski-Harabasz Score',\n",
    "    'Davies-Bouldin Score'\n",
    "])\n",
    "\n",
    "dic_ajustes = ['media', 'mediana', 'zero', 'trim']\n",
    "dic_metodos = ['kMeans', 'kMeansDTW', 'Aglomerative', 'DBAKmeansDTW0']\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b26d207",
   "metadata": {},
   "source": [
    "## Funções auxiliares"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "97a0031b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def ajuste_dados(num, dfOriginal):\n",
    "    df = dfOriginal.copy()\n",
    "    \n",
    "    match num:\n",
    "        case 0:\n",
    "            # ajuste 0 -> media\n",
    "            df.iloc[1:] = df.iloc[1:].apply(lambda col: col.fillna(col.mean()), axis=0)\n",
    "        case 1:\n",
    "            # ajuste 2 -> mediana\n",
    "            df.iloc[1:] = df.iloc[1:].apply(lambda col: col.fillna(col.median()), axis=0)\n",
    "        case 2:\n",
    "            #ajuste 3 -> zeros\n",
    "            df.iloc[1:] = df.iloc[1:].fillna(0)\n",
    "        case 3:\n",
    "            #ajuste 4 -> trim\n",
    "            timestamp = df.iloc[:, 0]\n",
    "            dados = df.iloc[:, 1:]\n",
    "\n",
    "            # Conta valores não nulos (validos) por coluna (sensor)\n",
    "            valid_lengths = dados.notna().sum(axis=0)\n",
    "\n",
    "            # Identifica o menor tamanho válido\n",
    "            min_length = valid_lengths.min()\n",
    "\n",
    "            # Corta todas as colunas para o menor tamanho\n",
    "            dados_cortados = dados.iloc[:min_length, :]\n",
    "\n",
    "            # Corta o timestamp também para manter alinhamento\n",
    "            timestamp_cortado = timestamp.iloc[:min_length]\n",
    "\n",
    "            # Reconstroi DataFrame final\n",
    "            df = pd.concat([timestamp_cortado.reset_index(drop=True), dados_cortados.reset_index(drop=True)], axis=1)\n",
    "\n",
    "    return df.T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "281828b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def separadataset(df):\n",
    "    # timestamp (eixo X)\n",
    "    timestamp = df.iloc[0].values\n",
    "\n",
    "    # séries temporais (linhas 1 a n)\n",
    "    series = df.iloc[1:].values\n",
    "    return timestamp, series\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6622089e",
   "metadata": {},
   "source": [
    "## Função Principal para o experimento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c7b0040",
   "metadata": {},
   "outputs": [],
   "source": [
    "#mudando os ajustes dos dados (normalização etc)\n",
    "for indice_ajuste in range(4):\n",
    "    #ajustando os dados no dfAjustado\n",
    "    dfAjustado = ajuste_dados(indice_ajuste,df_original)\n",
    "\n",
    "    print(\"indice ajuste: \", indice_ajuste)\n",
    "\n",
    "    #mudando os metodos\n",
    "    for indice_metodo in range(4):\n",
    "        print(\"indice do metodo: \", indice_metodo)\n",
    "    \n",
    "        #mudando a quantidade de clusters\n",
    "        for qnt_cluster in range(2,9):\n",
    "            print(\"Qnt de clusters: \", qnt_cluster)\n",
    "            \n",
    "            #copia o dfAjustado já transposto\n",
    "            df = dfAjustado.copy()\n",
    "\n",
    "            #pega o x e y\n",
    "            timestamp,series = separadataset(df)\n",
    "\n",
    "            #normaliza o X do DF\n",
    "            #X_scaled = TimeSeriesScalerMeanVariance().fit_transform(series)\n",
    "            X_scaled = StandardScaler().fit_transform(series)\n",
    "\n",
    "            # ----------- isso tudo é genérico, agora vai ser o switch case\n",
    "            match indice_metodo:\n",
    "\n",
    "                case 0: # K MEANS\n",
    "                    \n",
    "                    kmeans = KMeans(n_clusters=qnt_cluster, random_state=42)\n",
    "                    clusters = kmeans.fit_predict(X_scaled)\n",
    "                    #calcular inertia\n",
    "\n",
    "                case 1: # K MEANS DTW\n",
    "                    \n",
    "                    km_dtw = TimeSeriesKMeans(n_clusters=qnt_cluster, metric=\"dtw\", random_state=42)\n",
    "                    clusters = km_dtw.fit_predict(X_scaled)\n",
    "                    # calcular inetia\n",
    "\n",
    "                case 2: # AGLOMERATIVE DTW\n",
    "\n",
    "                    # Calcular a matriz de distância DTW\n",
    "                    distance_matrix = cdist_dtw(X_scaled)\n",
    "                    # Aplicar Hierarchical Clustering com DTW\n",
    "                    Z = linkage(distance_matrix, method='average')\n",
    "                    clusters = fcluster(Z, t=qnt_cluster, criterion='maxclust') #<- esse fclusters tá atrapalhando o plot\n",
    "                    #calcular inertia\n",
    "\n",
    "                case 3: # DBA K MEANS DTW\n",
    "\n",
    "                    km_dba = TimeSeriesKMeans(n_clusters=qnt_cluster, metric=\"dtw\", random_state=42)\n",
    "                    clusters = km_dba.fit_predict(X_scaled)\n",
    "                    #calcular inertia\n",
    "            \n",
    "                \n",
    "            # Calcular métricas de clusterização internas (sem y_true)\n",
    "            silhouette = silhouette_score(X_scaled, clusters)\n",
    "            calinski = calinski_harabasz_score(X_scaled, clusters)\n",
    "            davies = davies_bouldin_score(X_scaled, clusters)\n",
    "            # Crie um dicionário com os dados da nova linha\n",
    "\n",
    "            nova_linha = {\n",
    "                'Metodo': dic_metodos[indice_metodo],\n",
    "                'Ajuste': dic_ajustes[indice_ajuste],\n",
    "                'Quantidade_Cluster': qnt_cluster,\n",
    "                'Silhouette': silhouette,\n",
    "                'Calinski_Harabasz': calinski,\n",
    "                'Davies_Bouldin': davies\n",
    "                #inertia \n",
    "            }\n",
    "            #append inertia \n",
    "\n",
    "            # Crie um DataFrame a partir do dicionário da nova linha\n",
    "            df_nova_linha = pd.DataFrame([nova_linha])\n",
    "            # Concatene o DataFrame existente com o DataFrame da nova linha\n",
    "            df_metricas = pd.concat([df_metricas, df_nova_linha], ignore_index=True)\n",
    "\n",
    "            #df_metricas = df_metricas.append(dic_metodos[indice_metodo],dic_ajustes[indice_ajuste], qnt_cluster, silhouette, calinski, davies)\n",
    "            \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98dce912",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Metodo</th>\n",
       "      <th>Ajusten_clusters</th>\n",
       "      <th>Silhouette Score</th>\n",
       "      <th>Calinski-Harabasz Score</th>\n",
       "      <th>Davies-Bouldin Score</th>\n",
       "      <th>Ajuste</th>\n",
       "      <th>Quantidade_Cluster</th>\n",
       "      <th>Silhouette</th>\n",
       "      <th>Calinski_Harabasz</th>\n",
       "      <th>Davies_Bouldin</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>kMeans</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>media</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.611127</td>\n",
       "      <td>95.784832</td>\n",
       "      <td>0.555415</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>kMeans</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>media</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.643906</td>\n",
       "      <td>159.950503</td>\n",
       "      <td>0.469171</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>kMeans</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>media</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.685619</td>\n",
       "      <td>219.503266</td>\n",
       "      <td>0.421719</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>kMeans</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>media</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.577676</td>\n",
       "      <td>167.638380</td>\n",
       "      <td>0.452882</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>kMeans</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>media</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0.569179</td>\n",
       "      <td>197.288238</td>\n",
       "      <td>0.442196</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>132</th>\n",
       "      <td>DBAKmeansDTW0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>trim</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.604044</td>\n",
       "      <td>109.328089</td>\n",
       "      <td>0.543373</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>133</th>\n",
       "      <td>DBAKmeansDTW0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>trim</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.655691</td>\n",
       "      <td>140.065646</td>\n",
       "      <td>0.455797</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>134</th>\n",
       "      <td>DBAKmeansDTW0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>trim</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0.608917</td>\n",
       "      <td>116.610193</td>\n",
       "      <td>0.483689</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>135</th>\n",
       "      <td>DBAKmeansDTW0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>trim</td>\n",
       "      <td>7.0</td>\n",
       "      <td>0.546835</td>\n",
       "      <td>98.940498</td>\n",
       "      <td>0.705245</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>136</th>\n",
       "      <td>DBAKmeansDTW0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>trim</td>\n",
       "      <td>8.0</td>\n",
       "      <td>0.580369</td>\n",
       "      <td>92.087812</td>\n",
       "      <td>0.514584</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>137 rows × 10 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            Metodo Ajusten_clusters Silhouette Score Calinski-Harabasz Score  \\\n",
       "0           kMeans              NaN              NaN                     NaN   \n",
       "1           kMeans              NaN              NaN                     NaN   \n",
       "2           kMeans              NaN              NaN                     NaN   \n",
       "3           kMeans              NaN              NaN                     NaN   \n",
       "4           kMeans              NaN              NaN                     NaN   \n",
       "..             ...              ...              ...                     ...   \n",
       "132  DBAKmeansDTW0              NaN              NaN                     NaN   \n",
       "133  DBAKmeansDTW0              NaN              NaN                     NaN   \n",
       "134  DBAKmeansDTW0              NaN              NaN                     NaN   \n",
       "135  DBAKmeansDTW0              NaN              NaN                     NaN   \n",
       "136  DBAKmeansDTW0              NaN              NaN                     NaN   \n",
       "\n",
       "    Davies-Bouldin Score Ajuste  Quantidade_Cluster  Silhouette  \\\n",
       "0                    NaN  media                 2.0    0.611127   \n",
       "1                    NaN  media                 3.0    0.643906   \n",
       "2                    NaN  media                 4.0    0.685619   \n",
       "3                    NaN  media                 5.0    0.577676   \n",
       "4                    NaN  media                 6.0    0.569179   \n",
       "..                   ...    ...                 ...         ...   \n",
       "132                  NaN   trim                 4.0    0.604044   \n",
       "133                  NaN   trim                 5.0    0.655691   \n",
       "134                  NaN   trim                 6.0    0.608917   \n",
       "135                  NaN   trim                 7.0    0.546835   \n",
       "136                  NaN   trim                 8.0    0.580369   \n",
       "\n",
       "     Calinski_Harabasz  Davies_Bouldin  \n",
       "0            95.784832        0.555415  \n",
       "1           159.950503        0.469171  \n",
       "2           219.503266        0.421719  \n",
       "3           167.638380        0.452882  \n",
       "4           197.288238        0.442196  \n",
       "..                 ...             ...  \n",
       "132         109.328089        0.543373  \n",
       "133         140.065646        0.455797  \n",
       "134         116.610193        0.483689  \n",
       "135          98.940498        0.705245  \n",
       "136          92.087812        0.514584  \n",
       "\n",
       "[137 rows x 10 columns]"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_metricas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "82b2bce2",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_metricas.to_csv('Metricas.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
